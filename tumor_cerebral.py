# -*- coding: utf-8 -*-
"""Tumor cerebral

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kh9gUVNs16ZQOPNp4wadzsUQbxFp9AmY

## Importação das bibliotecas
"""

import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score
import torch
torch.__version__
#!pip install torch==1.4.0
import torch.nn as nn

"""## Base de dados"""

np.random.seed(123)
torch.manual_seed(123)

previsores = pd.read_csv('/content/Brain Tumor.csv')
previsores.shape

previsores.head()

#sns.countplot(previsores)
previsores_treinamento, previsores_teste = train_test_split(previsores.iloc[:,2:], test_size = 0.25)
#print(previsores_treinamento)
previsores_treinamento.shape

previsores_teste.shape

"""## Transformação dos dados para tensores"""

previsores_treinamento = np.array(previsores_treinamento)
#print(previsores_treinamento)
previsores_treinamento = torch.from_numpy(previsores_treinamento).float()

type(previsores_treinamento)

if previsores_treinamento.shape[1] == 13:
    rotulo = 'tipo'
else:
    rotulo = 'label'

train_dataset = torch.utils.data.TensorDataset(previsores_treinamento[:,:-1], previsores_treinamento[:,-1])
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)

"""## Construção do modelo"""

# 12 -> 7 -> 7 -> 1
# (entradas + saida) / 2 = (12 + 1) / 2 = 7
classificador = nn.Sequential(
    nn.Linear(in_features=12, out_features=7),
    nn.ReLU(),
    nn.Linear(7, 7),
    nn.ReLU(),
    nn.Linear(7, 1),
    nn.Sigmoid()
)
classificador.parameters

criterion = nn.BCELoss()
optimizer = torch.optim.Adam(classificador.parameters(), lr=0.001, weight_decay=0.0001)

"""## Treinamento do modelo"""

for epoch in range(100):
  running_loss = 0.

  for data in train_loader:
    inputs, labels = data
    #print(inputs)
    #print('-----') 
    #print(labels)
    optimizer.zero_grad()

    outputs = classificador(inputs) # classificador.forward(inputs)
    #print(outputs)
    loss = criterion(outputs, labels.unsqueeze(1))
    #print(loss)
    loss.backward()
    optimizer.step()

    running_loss += loss.item()
  print('Época %3d: perda %.5f' % (epoch+1, running_loss/len(train_loader)))